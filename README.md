HELAPP â€“ AI Virtual Assistant with Voice & Eye Control ğŸ‘ï¸ğŸ™ï¸ğŸ’»

HELAPP is a smart virtual assistant powered by voice commands and real-time eye tracking using computer vision. Built with Python, this assistant helps users control their computer entirely hands-free, making it especially useful for individuals with limited mobility or accessibility needs.
ğŸŒŸ Features

âœ… Voice Recognition with Speech Commands
âœ… Text-to-Speech Feedback
âœ… Eye-Tracking Mouse Movement with MediaPipe + OpenCV
âœ… Voice-Controlled Automation (open/close apps, browser tabs, music, Google/YouTube search, etc.)
âœ… Joke Generator for User Engagement
âœ… Weather Information via WeatherStack API
âœ… System Commands (volume control, scroll, shutdown, restart, lock, etc.)
âœ… Typing via Voice Input
âœ… Screenshot Capture by Voice
âœ… Basic Calculator (voice-based math expression parsing)
âœ… Wikipedia Search Integration
âœ… IP Address Retrieval
âš™ï¸ Technologies Used

    Python

    SpeechRecognition

    pyttsx3 (Text-to-Speech)

    MediaPipe & OpenCV (Eye and face tracking)

    pyautogui (Mouse & keyboard automation)

    Wikipedia API

    WeatherStack API

    pywhatkit (WhatsApp & YouTube automation)

    Threading (Concurrent eye-tracking and voice interaction)

ğŸ¯ Use Cases

    Hands-free system control for users with disabilities.

    Assistive tech for productivity and automation.

    Entertainment (jokes, YouTube, Spotify).

    Education and information retrieval via voice.

ğŸ“¦ Installation

Clone the Repository:

    git clone https://github.com/yourusername/helapp-virtual-assistant.git
    cd helapp-virtual-assistant

Install Required Packages:

    pip install -r requirements.txt

Run the Application:

    python main.py

Make sure you have a working microphone and webcam connected.
ğŸ§  Eye Tracking Details

The assistant uses MediaPipe FaceMesh to detect and track landmarks around the eyes. Cursor movement is controlled using eye gaze, and left-eye blink triggers mouse clicks. You can quit the eye-tracking loop by saying:

    â€œQuit eye-trackingâ€ or â€œGo to sleepâ€

ğŸ” API Keys Required

    WeatherStack: Replace api_key in the get_weather() function with your own WeatherStack API key.

    Wikipedia: No API key required.

ğŸ§ª Sample Voice Commands

    â€œOpen YouTubeâ€

    â€œSearch on Googleâ€

    â€œTell me a jokeâ€

    â€œWhat is the weather in Khorog?â€

    â€œOpen WhatsAppâ€

    â€œType Hello, how are you?â€

    â€œCalculate 7 plus 5â€

    â€œTake a screenshotâ€

    â€œShut down the systemâ€

ğŸš§ Limitations

    Eye tracking performance may vary based on camera quality and lighting.

    Voice commands depend on clear speech and background noise levels.

    Not cross-platform; optimized for Windows OS.

ğŸ™Œ Credits

Created by Meder, Mariiam, Mustafo, and Firdous as a project to support and empower disabled users through innovative AI and ML-based interaction.
ğŸ“œ License

This project is open-source and available under the MIT License.
